The names in LICENSES do not necessarily reveal the Authorâ€™s names for this paper.


hyperbolic-layers:
In order to reproduce the results for tables 1, one can use the hyper-parameters we provided in the appendix.
For table 3, the user need to uncomment the layers the re-run the expriments (for example py_hnn/models/encoders.py PGCN encode function line 115)

Example:
python3 -W ignore train.py --model PGAT  --dim 64  --n-heads 4  --lr 0.05    --dataset cora    --act relu --weight-decay 0.0005  --dropout 0.6  --optimizer  RiemannianAdam --manifold PoincareBall


Multi-Relational Models:

For table 2, the script in the folder are self-sufficient.

Example: multirelational-normalized/run_MURP.sh


torch-RGCN: 
You can simply use one of the configs in the config files. 
The names with h- at the beginning (e.g. hrgcn) indicate 
our hyperbolic normalization is added to the model.

Example:    
python3 classify_nodes.py with configs/hrgcn/nc-AIFB.yaml


GCNII repo:
Use example in semi.sh. For the hyperbolic hyper-parameters such as the curvature and scale, we have done a naive hyper-parameter search.
for experiments, try scales = 1, 3, 5, 10 and for curvature = 0.25, 0.5, 1, 1.5


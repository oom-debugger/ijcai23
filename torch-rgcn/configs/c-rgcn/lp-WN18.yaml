dataset:
  name: WN18

training:
  epochs: 2000  # Limit the number of training epochs
  negative_sampling:
    sampling_rate: 10  # Number of negative samples to produce per positive triple
    head_prob: 0.5  # Ratio of corrupting heads (i.e. 0.5 means corrupt 50% heads and 50% tails)
  optimiser:
    algorithm: adam
    weight_decay: 0.0
    learn_rate: 0.01
  use_cuda: True  # If true, model is trained on GPU

encoder:
  model: c-rgcn
  num_layers: 1  # Number of graph convolution layers
  node_embedding: 128  # Size for node and relation embedding
  hidden1_size: 16  # Size of first hidden layer - Dimension to compress node embeddings to (ideally much smaller than embedding_size)
  edge_dropout:
    general: 0.5  # Dropout rate for all edges (except self-loops)
    self_loop: 0.2  # Dropout rate for self-loops
    self_loop_type: schlichtkrull-dropout
  weight_init: schlichtkrull-normal  # Weight Initialisation
  include_gain: False  # Add scaling factor depending on the type of non-linearity function used
  bias_init: zeros  # Bias Initialisation (Delete this line to remove biases)

decoder:
  model: distmult
  l2_penalty_type: 'schlichtkrull-l2'
  l2_penalty: 0.01
  weight_init: standard-normal
  include_gain: False  # Add scaling factor depending on the type of non-linearity function used

evaluation:
  final_run: False  # If true, evaluates model on test set. Otherwise, validation set is used
  filtered: True  # If true, reports filtered metrics. Otherwise, raw metrics are computed.
  check_every: 50  # Evaluate model at regular intervals (By default, every 2000 epochs)
  batch_size: 32  # Number of triples per evaluation batch
  verbose: True  # Show evaluation progress bar
